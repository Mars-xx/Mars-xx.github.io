<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-目标检测：小目标检测" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" class="article-date">
  <time datetime="2020-01-18T13:06:37.732Z" itemprop="datePublished">2020-01-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测：小目标检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h1><p>[TOC]</p>
<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p><strong>主要难点：</strong></p>
<ol>
<li>目标尺寸过小，导致可提取的特征较少，经过几次卷积之后的深层已经提取不到特征。</li>
<li>目标尺寸过小，导致匹配上的anchor数量较少，甚至匹配不到anchor，导致无法充分对其进行学习。</li>
<li>目标尺寸过小，使得背景中的负样本相对来说更多，导致正负样本更加不平衡，容易影响学习方向。</li>
</ol>
<p><strong>主要措施：</strong></p>
<ol>
<li>去掉深层的特征层，保留底层特征，并进行多尺度特征融合。</li>
<li>对图像进行放大：放大能够有效提高小目标检测的召回率，但是会降低算法速度</li>
<li>数据增广：减少正负样本类别不平衡，多次复制粘贴小目标到图像中不同位置</li>
<li>增加小目标的局部上下文信息，增加更多的上下文信息有助于检测</li>
<li>设置更加密集合理的anchor，保证小目标能够被充分匹配上。</li>
<li>利用GAN对小目标检测超分辨率重建（PGAN）</li>
</ol>
<h2 id="2-S3FD"><a href="#2-S3FD" class="headerlink" title="2. S3FD"></a>2. S3FD</h2><blockquote>
<p>论文名称：S3FD: Single Shot Scale-invariant Face Detector</p>
<p>论文地址：<a href="https://arxiv.org/pdf/1708.05237.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1708.05237.pdf</a></p>
</blockquote>
<p><strong>1. 算法概述</strong></p>
<p>本文针对人脸检测中小尺度人脸检测的难点，分析了造成该问题的主要原因，并给出了相应的优化办法，提出了一种 $S^3FD$ 算法，该算法主要以 SSD 和 RPN 这两种经典的 anchor-based 算法为基础，并针对 anchor-based 目标检测算法的不足，进行了相应的改进，最后达到了 state-of-the-art 的效果。</p>
<p><strong>2. 问题分析</strong></p>
<p>现有的目标检测算法主要以 anchor-based 的方法为主，该方法通过对一系列预置的不同尺度和长宽比的 anchors 进行分类和回归，来确定物体的类别和定位目标的位置。然而，随着目标尺寸的减少，anchor-based 的算法性能急剧下降，作者分析了造成该现象的主要原因，概括为如下几点：</p>
<p><img src="image/1578105994199.png" alt="1578105994199"></p>
<ul>
<li><p>a) 浅层的卷积网络的步幅过大：步幅过大，而目标又小，使得特征被高度压缩，导致几乎无特征可以检测。</p>
</li>
<li><p>b) 多重不匹配问题：小脸尺寸、anchor 尺寸、感受野三者不匹配，特别是小脸尺寸与另外两者极度不匹配。</p>
</li>
<li><p>c) anchor 的匹配度不够高：由于 anchor 的尺度是离散的，而实际的目标尺度是连续的，这些尺度和 anchor 相差过大的目标（特别是小目标）由于IOU较低无法很好地匹配上anchor，故得不到充分学习，召回率下降。</p>
</li>
<li><p>d) 背景中的负样本数量过多：为了检测小目标，使用了大量的小尺度anchor，同时也引入了大量的背景负样本，一方面造成正负样本极度不均衡，另一方面这么多负样本加大了误检的概率。</p>
</li>
</ul>
<p><strong>3. 算法创新</strong></p>
<p>针对上述几个问题，作者设计了 $S^3FD$ 算法，该算法主要基于RPN和SSD网络，对人脸进行多尺度特征检测，其网络结构如下图所示，可见基本和SSD的网络结构差不多：</p>
<p><img src="image/1578122566104.png" alt="1578122566104"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">算法的主要贡献主要有三个方面：</span><br><span class="line">1. 针对anchor多重不匹配，重新设计了anchor的分布，并提出了等比例间隔策略。</span><br><span class="line">2. 针对anchor匹配度不高，提出了一种尺度补偿策略，来提高对小目标的召回率。</span><br><span class="line">3. 针对背景中负样本数量过多，引入最大背景标签策略，来降低背景中负样本的误检率。</span><br></pre></td></tr></table></figure>

<p><strong>3.1 Equal-proportion interval principle(EPIP)</strong></p>
<p><img src="image/1578124960263.png" alt="1578124960263"></p>
<p>在6个不同层的 feature map 上分别设置长宽比为1:1的 anchors，stride 尺度从4~128逐层增倍（stride 其实就是 feature map 相对于原图的采样间隔，6个检测层逐层增倍），anchor的尺度始终保持为stride的4倍，如conv3_3层的anchor映射为原图就是每4个 pixels 设置一个尺度为16x16的 anchor，conv4_3 层的 anchors 映射为原图就是每8个 pixels 设置一个尺度为32x32的 anchor，这样就确保不同尺度的anchor有相同的采样密度，从而保证不同尺度的人脸可以匹配到近似相同数量的anchor。</p>
<p><strong>3.2 Scale compensation anchor matching strategy(SCAMC)</strong></p>
<p>由于人脸的尺度是连续的，而预置的anchor尺度是离散的，这样会导致那些与anchor尺度相差过大的人脸（尤其是小尺度人脸）与anchor的IOU过小，从而无法很好地匹配到anchor，导致无法充分学习，从而影响召回率。为了解决上述问题，作者提出了一种双阶段的匹配策略，如下：</p>
<p>1）阶段一：遵循SSD的匹配策略，首先将 groundtruth 匹配给与之IOU最大的anchor，保证至少有一个anchor与之匹配，然后在剩余未匹配的的 anchor 中，选择与 grounthtruth 的IOU大于某个阈值的所有anchor，将其匹配给该 groundtruth 以增加正样本的数量，为了提高小目标的匹配度，本文将IOU阈值从0.5降低为0.35。</p>
<p>2）阶段二：经过阶段一后仍有许多小目标没有匹配到足够的 anchor，为了增加该部分小目标的正样本数量，对该部分小目标扩充匹配的 anchor，为此，需要进一步降低阈值至0.1，然后按照IOU选择top-N的anchor与该部分小目标匹配，N为阶段一中那些正常匹配的groundtruth匹配到的anchor数目的均值。</p>
<p><strong>3.3 Max-out background label(MOBL)</strong></p>
<p><img src="image/1578128226446.png" alt="1578128226446"></p>
<p>为了检测小目标，我们需要设置密集的小尺寸的 anchor 来尽量覆盖图像，上图给出了各层的anchor数量，可以看出用于检测小目标的底层anchor占比最大，这就引入了大量的负样本，这么多负样本的引入不可避免的会带来不少误检。为了解决上述问题，作者在用于检测小目标的conv3_3层使用了一种叫作最大输出背景标签(MOBL) 的策略，对该层的每一个 anchor 做 $N_{m}$ 次背景类别的预测（相当于设计$N_{m}$个背景分类器），然后选择预测为背景最高的分数，作为该anchor最终被为背景的分数，之前只预测一次，现在预测多次，这样就加大了anchor被分为背景的概率，从而可以一定程度上减小误检。</p>
<h2 id="3-ZCC"><a href="#3-ZCC" class="headerlink" title="3. ZCC"></a>3. ZCC</h2><blockquote>
<p>论文名称：Seeing Small Faces from Robust Anchor’s Perspective</p>
<p>论文地址：<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8578636" target="_blank" rel="noopener">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8578636</a></p>
</blockquote>
<p><strong>1. 算法概述</strong></p>
<p>本文就现有anchor-based算法在检测小尺度人脸时漏检率高的现象，作者分析并认为导致上述问题的原因是现有算法中anchor的设计保证不了小人脸与anchor boxes之间足够的重叠率，从而导致这些tiny face没法被充分训练。为此，作者提出了EMO分数来解释上述现象，并给出了几种新的anchor设计策略来解决上述问题。</p>
<p><strong>2. 问题分析</strong></p>
<p><img src="image/1578220204823.png" alt="1578220204823"></p>
<ul>
<li><p>a) 显示了不同尺寸的人脸的平均召回率，可以看出随着尺寸的减少召回率不断降低。</p>
</li>
<li><p>b) 显示了不同尺寸的人脸的与anchor的平均IOU，可见小尺寸人脸的IOU最小，小的IOU一方面导致训练的时候，不能匹配上anchor，从而没法当做正样本训练，另一方面，较小IOU的正样本也更难回归调整，上述原因导致了图(a)中召回率的低下。</p>
</li>
<li><p>c) 本文提出的anchor机制，比之前的anchor机制有着更高的IOU，与小目标更加匹配。</p>
</li>
</ul>
<p><strong>3. 算法创新</strong></p>
<p>作者发现小脸召回率低的原因主要是因为小脸与anchor的IOU低，作者认为提高小目标IOU的关键在于两点：1）减少anchor的间隔；2）减少anchor与与groundtruth中心的距离，为此作者提出了四种改进策略。</p>
<p><strong>3.1 特征图上采样</strong></p>
<p>对于一般的anchor-based算法，anchor的间隔就等于feature map下采样的间隔（$s_{A}=s_{F}$)，要想减少anchor的间隔，可以通过加大feature map的尺寸来间接实现（feature map尺寸变大，则$s_F$减少，由于$s_{A}=s_{F}$，故$s_{F}$也减少），作者提出了如下三种上采样的网络结构（具体参见原文），来提升feature map的尺寸。</p>
<p><img src="image/1578229187668.png" alt="1578229187668"></p>
<p><strong>3.2 增加偏移的Anchor</strong></p>
<p>特征图上采样没有改变$s_{A}=s_{F}$的关系，本节通过增加额外偏移的anchor，使得 $s_{A}&lt;s_{F}$ ，从而减少anchor的间隔。具体的，如下图所示，图中每一个点代表 feature map上的一个特征点，一般算法的 anchor 的中心都是设置在feature map的每一个点上，从而才有了$s_{A}&lt;s_{F}$，但是为了应对小目标，需要设置更加密集的anchor，因此完全可以在这些点之间也设置anchor，从而降低anchor的间隔，增大小目标的IOU。</p>
<p><img src="image/1578230847230.png" alt="1578230847230"></p>
<p>上述思想与FaceBoxes论文中增加anchor覆盖率的方法一样，如下：</p>
<p><img src="image/1578145505338.png" alt="1578145505338"></p>
<p>*<em>3.3 图像轻微移动 *</em></p>
<p>由于anchor是离散的，而目标的实际位置是连续的，对于特小目标，还是会有一些由于匹配到的IOU很低，从而没法被当做正样本来训练，为了进一步增强，训练的过程中，可以每次给图像进行轻微的移动，随机移动一个偏移量，从而加大小目标被匹配上的概率，从而保证所有的小目标都有机会被训练到，偏移量范围为$[0,s_A/2-1]$。</p>
<p><strong>3.4 难检样本补偿</strong></p>
<p>与S3FD中的算法几乎没有差别，可以分布两步，具体如下：</p>
<p>1）阶段一：遵循SSD的匹配策略，首先将 groundtruth 匹配给与之IOU最大的anchor，保证至少有一个anchor与之匹配，然后在剩余未匹配的的 anchor 中，选择与 grounthtruth 的IOU大于某个阈值的所有anchor，将其匹配给该 groundtruth 以增加正样本的数量，为了提高小目标的匹配度，本文将IOU阈值从0.5降低为0.35。</p>
<p>2）阶段二：经过阶段一后仍有许多小目标没有匹配到足够的 anchor，为了增加该部分小目标的正样本数量，对该部分小目标扩充匹配的 anchor，为此，需要进一步降低阈值至0.1，然后按照IOU选择top-N的anchor与该部分小目标匹配，N为阶段一中那些正常匹配的groundtruth匹配到的anchor数目的均值。</p>
<h2 id="0-总结"><a href="#0-总结" class="headerlink" title="0. 总结"></a>0. 总结</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" data-id="ck5jlw19r0004gil78eujgn4p" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-目标检测：相关基础知识" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="article-date">
  <time datetime="2020-01-18T13:06:37.732Z" itemprop="datePublished">2020-01-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">目标检测：相关基础知识</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h1><p>[TOC]</p>
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p><strong>1. 精确度:</strong></p>
<p>精确度又称“查准率”，就是所有被预测为正类的样本中，实际为正类的样本所占的比例，如下公式所示：<br>$$<br>Precision=\frac{T P}{T P+F P}<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; 目标检测中指预测为目标中有多少为实际目标</span><br></pre></td></tr></table></figure>

<p><strong>2. 召回率:</strong></p>
<p>召回率又称“查全率”，就是指所有的正样本，被成功预测为正类的比例，如下公式所示：<br>$$<br>Recall=\frac{T P}{T P+F N}<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; 目标检测中指所有的目标中，有多少被成功找出来了</span><br></pre></td></tr></table></figure>

<p><strong>3. 虚警率:</strong></p>
<p>虚警率又称误检率，就是所有被预测为正类的样本中，实际为正类的样本所占的比例，如下公式所示：<br>$$<br>1 - Precision=\frac{F P}{T P+F P}<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; 目标检测中指被预测为目标的样本中有多伪目标</span><br></pre></td></tr></table></figure>

<p><strong>4. 漏警率:</strong></p>
<p>漏警率又称漏检率，就是指所有的正样本，被成功预测为正类的比例，如下公式所示：<br>$$<br>1 - Recall=\frac{F N}{T P+F N}<br>$$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; 目标检测中指所有的目标中，有多少未被检测出来</span><br></pre></td></tr></table></figure>



<h2 id="类别不平衡"><a href="#类别不平衡" class="headerlink" title="类别不平衡"></a>类别不平衡</h2><p><strong>目标检测任务中，样本包括哪些类别呢？</strong> </p>
<ul>
<li>正样本：标签区域内的图像区域，即目标图像块；</li>
<li>负样本：标签区域以外的图像区域，即图像背景区域；</li>
<li>易分正样本：容易正确分类的正样本，在实际训练过程中，该类占总体样本的比重非常高，单个样本的损失函数较小，但是累计的损失函数会主导损失函数；</li>
<li>易分负样本：容易正确分类的负样本，在实际训练过程中，该类占的比重非常高，单个样本的损失函数较小，但是累计的损失函数会主导损失函数；</li>
<li>难分正样本：错分成负样本的正样本，这部分样本在训练过程中单个样本的损失函数教高，但是该类占总体样本的比例教小；</li>
<li>难分负样本：错分成正样本的负样本，这部分样本在训练过程中单个样本的损失函数教高，但是该类占总体样本的比例教小。</li>
</ul>
<p><strong>那么什么是样本不平衡问题？</strong></p>
<p>所谓的样本不平衡问题是指在训练的时候各个类别的样本数量极不均衡。以基于深度学习的单阶段目标检测为例，样本类别不均衡主要体现在两方面：<strong>正负样本不均衡</strong>（正负样本比例达到 1:1000）和<strong>难易样本不均衡</strong>（简单样本主导 loss）。一般在目标检测任务框架中，保持正负样本的比例为 1:3（经验值）。</p>
<p>对于一个样本，如果它能很容易地被正确分类，那么这个样本对模型来说就是一个简单样本，模型很难从这个样本中得到更多的信息；而对于一个分错的样本，它对模型来说就是一个困难的样本，它更能指导模型优化的方向。</p>
<p>对于单阶段分类器来说，简单样本的数量非常大，他们产生的累计贡献在模型更新中占主导作用，而这部分样本本身就能被模型很好地分类，所以这部分的参数更新并不会改善模型的判断能力，这会导致整个训练变得低效。</p>
<p><strong>实际训练过程中如何划分正负样本训练集？</strong></p>
<p>近年来，不少的研究者针对样本不均衡问题进行了深入研究，比较典型的有 <strong>OHEM</strong> [1]（在线困难样本挖掘）、<strong>S-OHEM</strong>[2]、<strong>A-Fast-RCNN</strong>[3]、<strong>Focal Loss</strong>[4]、<strong>GHM</strong>[5]（梯度均衡化）</p>
<blockquote>
<p> 参考博文：<a href="http://www.sohu.com/a/306064501_500659" target="_blank" rel="noopener">http://www.sohu.com/a/306064501_500659</a></p>
</blockquote>
<h2 id="Anchor机制"><a href="#Anchor机制" class="headerlink" title="Anchor机制"></a>Anchor机制</h2><p>Anchor的本质还是候选框，只是相比滑动窗这种粗暴的方法，减少了很多框的数量，而且会结合位置回归，从而可以更加准确地定位出目标的位置。Anchor技术将问题转换为”这个固定参考框中有没有认识的目标（分类），如果有，这个目标框偏离参考框多远，需要怎么调整（回归）”。在设计了不同尺度和比例的候选框后，DNN学习如何将这些候选框进行分类：是否包含object和包含什么类别的object，对于postive的anchor会学习如何将其回归到正确的位置。它扮演的角色和传统检测算法中的滑动窗口等机制比较类似。</p>
<p>Anchor based 目标检测算法的输入是图片、输出的是一个表示各个anchor的classification和localization的预测值。以人脸检测为例，并假设每张图像设置了N个anchor，那么输入一张待检测图像，输出的就是一个[N, (2 + 4)]维矩阵，其中2表示分类的预测，是否为人脸，4表示（x,y,w,h）相对于anchor的offset的预测。</p>
<p><strong>Anchor based的局限性：</strong></p>
<ol>
<li>Anchor的设置需要手动去设计，对不同数据集也需要不同的设计，造成使用较为麻烦。</li>
<li>离散的 anchor 尺度设定会导致一些物体无法很好的匹配到 anchor，从而导致遗漏。</li>
<li>Anchor的匹配机制使得极端尺度的目标被匹配到的概率相对于大小适中的目标概率低很多，导致网络不太容易学习好这些极端样本的特征。</li>
<li>Anchor的庞大数量使得存在严重的正负不平衡问题，正样本相对于负样本少很多，需要控制正负样本比。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" data-id="ck5jlw19s0005gil742ju2vw4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-目标检测：FPN" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9AFPN/" class="article-date">
  <time datetime="2020-01-18T13:06:37.728Z" itemprop="datePublished">2020-01-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9AFPN/">目标检测：FPN</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h1><p>[TOC]</p>
<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>不同尺度和极端尺度的目标检测是目标检测的一项基本挑战，为了解决多尺度目标检测，先后涌现了图像金字塔结构，多尺度特征检测检测，和本文提出的特征金字塔网络（FPN）。相比于其他结构，特征金字塔网络可以很好的解决不同尺度的目标检测，FPN 还融合了不同层的特征，使得高分辨率的底层拥有了高层的语义特征，因此对小目标的检测更有利。</p>
<h2 id="原理详解"><a href="#原理详解" class="headerlink" title="原理详解"></a>原理详解</h2><p><strong>多尺度检测结构对比</strong></p>
<p>识别不同尺寸的目标是目标检测的一项基本挑战，为了解决多尺度目标检测，出现了以下四种基本结构，作者总结了以往的几种多尺度检测的方法，比对了他们的不足，然后引出了本文的特征金字塔网络——FPN。</p>
<p><img src="../../../../%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/image/1578363231206.png" alt="1578363231206"></p>
<ul>
<li>a) 图像金字塔结构：早期的多尺度检测方法，使用图像金字塔构建特征金字塔，先将图像逐层降采样，然后分层提取特征，再逐层检测，显而易见的缺点就是速度很慢。</li>
<li>b) 仅用顶层特征检测：Faster R-CNN 中用的方法，设置不同尺度的anchor，但是仅有顶层特征来检测，缺点是对小目标检测效果很不好，因为顶层分辨率低，小目标的特征容易消失。</li>
<li>c) 多层特征分别检测：SSD 中用的方法，是对图像金字塔的改进，利用卷积网络自带的池化效果来构建不同尺度的特征图，再多层分别检测，相比图像金字塔提高了速度，而且也提高了对不同尺度的适应性。但是由于各种特征还是孤立的，没有进行融合，使得浅层分辨率高，但是语义信息不够，因此对小目标的检测还是不好。</li>
<li>d) 特征金字塔网络：进一步改进，将多层特征进行融合，融合了高层的语义特征和浅层的高分辨率信息，使得各层的特征都进行了强化，提高了对小目标的检测能力，而且也没有额外增加过多运算量。</li>
</ul>
<p><strong>FPN 网络结构</strong></p>
<p>FPN 将任意大小的图像作为输入，并以全卷积的方式输出不同尺寸的特征图，该过程与具体的backbone无关，作者使用了 ResNet 作为backbone，FPN 的结构如下，采用了自下而上、自上而下以及横向连接的结构进行多尺度特征融合。</p>
<p><img src="image/1578381917613.png" alt="1578381917613"></p>
<ul>
<li><strong>自下而上结构</strong>：自下而上的结构，是backbone的前向传播，得到一些列不同层的 feature map ，各层的尺度相差2倍。在ResNet中使用了 {conv2, conv3, conv4, conv5}，由于 conv1的引入会消耗太多内存，故舍去。</li>
<li><strong>自上而下结构</strong>：自上而下的结构，就是将具有较高语义信息的高层特征图进行上采样得到大尺度的特征图。</li>
<li><strong>横向连接结构</strong>：横向连接就是将自下而上和自上而下的具有相同尺度的特征进行融合，这样融合的新特征图就同时具有了高层的语义特征和底层的高分辨率信息。</li>
</ul>
<p><strong>FPN的特征融合方式</strong></p>
<p><img src="image/v2-38ecc58507df271897fdae605868d6e1_r.jpg" alt="preview"></p>
<p>FPN 具体的融合方式如图所示，就是简单地将对应尺度的特征图进行逐元素相加，融合的过程中为了降低维度，首先，需要通过1x1的卷积核来减少原特征金字塔中各层特征图的通道数，将各层通道数固定为256；然后，对顶层特征进行2倍上采样，形成高分辨率特征图，再利用横向连接将上采样结果与原特征金字塔中对应的层进行逐像素相加得到融合结果；最后，再额外利用3x3的卷积层，将融合结果平滑一下，得到最终语义增强后的特征金字塔（ps：作者解释道特征可以直接按照像素相加，是因为做了端到端的训练，所以网络可以学习到怎么把底层的高分辨率信息和顶层的语义信息进行结合，以达到提高检测性能的目的）。</p>
<p><strong>实验结果</strong></p>
<p>作者利用FPN对RPN网络进行了优化，做了6组对比实验：(a) 基于conv4的RPN（原始的RPN）；(b）基于conv5的RPN； (c) FPN；(d) 只用自底向上的多层特征，没有自顶向下的特征； (e) 有自顶向下的特征，但是不用横向连接，只是单纯的增加特征的分辨率； (f) 用了自顶向下的特征，也用了横向特征融合，但是只用最后的P2作为预测。各组实验的对比的结果如下表所示：</p>
<p><img src="image/1578452767464.png" alt="1578452767464"></p>
<p>通过表格可以得到如下结论：</p>
<ul>
<li>对比实验(a)(b)(c)，可以看出基于特征金字塔的方式，极大的提高了各个尺度框的召回率。尤其是小物体的检测效果提升非常明显。</li>
<li>对比实验(a)和(d)，可以看出单纯用各个层次的特征做预测，相比于只用conv4做预测，效果提升非常有限。</li>
<li>对比实验(a)和(e)，可以看出单纯的放大特征图，但是不融合，反而性能会下降。</li>
<li>对比实验(a)和(f)，可以看出单纯用融合度最高的特征层（P2）来做预测，提升效果也很有限。</li>
<li>对比实验(c)和(f)，可以看出相比于（f），（c）有两点不同：一个是使用了多尺度的特征层做预测，另一个是不同尺度的框被映射到不同的特征层。从(c)的效果明显好于(f)来看，这种尺度信息分离的方式是非常必要的。</li>
</ul>
<p>通过以上对比可以看出，自顶向下的特征、横向连接、尺度分离、多个层次的预测是提升RPN性能几大功臣。</p>
<h2 id="总结概括"><a href="#总结概括" class="headerlink" title="总结概括"></a>总结概括</h2><p>FPN 将顶层的语义信息和底层的高分辨率信息进行了很好的融合，得到一个增强后的特征金字塔，这个特征金字塔比未经过融合直接由自下而上生成的特征金字塔要具有更强的特征表达能力，因此检测的性能更好，而且并没有引入太多额外计算；FPN 也比经由图像金字塔生成的特征金字塔要省时省内存很多。因此，FPN 是解决多尺度目标检测和小目标检测的一个比较好的方法。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9AFPN/" data-id="ck5jlw19n0001gil7enfyfk19" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-目标检测：RetinaNet" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ARetinaNet/" class="article-date">
  <time datetime="2020-01-18T13:06:37.728Z" itemprop="datePublished">2020-01-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ARetinaNet/">目标检测：RetinaNet</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h1><p>[TOC]</p>
<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>作者认为目标检测限制目标检测精度的一个主要原因是，训练阶段的正负样本极度不均衡。一般的Two-stage主要通过第一阶段的RPN网络，来去除大量背景负样本；而one-stage算法主要通过控制正负样本比以及OHEM（在线困难样本挖掘）技术来平衡正负样本。而在本文中，作者主要借助损失函数来控制正负样本，作者对传统的交叉熵分类损失函数进行了改进，提出了Focal Loss，以降低简单易分样本的损失，从而聚焦在对难分样本的训练上。本文提出的目标检测算法 RetinaNet 兼顾了检测速度和检测速度，达到了SOTA的水平。</p>
<h2 id="原理详解"><a href="#原理详解" class="headerlink" title="原理详解"></a>原理详解</h2><h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p><strong>类别不均衡问题</strong></p>
<p>one-stage 算法检测精度低的一个主要原因是类别不均衡，造成这个问题的原因主要有两个：1）由于绝大多数的样本是易分类样本，可以进一步学习的东西很少，导致训练过程十分低效；2）大量的简单负样本会主导训练的方向，从而影响特征的学习。因此需要对正负样本进行均衡，对难易样本进行均衡，常见的解决办法是进行困难负样本挖掘。</p>
<p>two-stage 的检测算法，通过两步来控制样本不均衡现象：在第一阶段，使用候选区建议网络来极大地减少负样本数量，而且由于使用了建议算法，因此也剔除了绝大多数了易分负样本；在第二阶段，我们使用1:3的正负样本比进一步控制这种不平衡现象。不同于two-stage的策略， Focal Loss 旨在使用损失函数来解决 one-stage 检测算法中的类别不均衡问题。</p>
<p><strong>Focal Loss</strong></p>
<p>Focal Loss 是动态缩放的交叉熵损失函数，是为了解决one-stage目标检测算法在训练过程中正负样本极度不均衡而设计的分类损失函数。他主要通过动态地调节系数来控制正负样本比，系数会随着正确类别的置信度的增加而衰减，从而减少易分类样本的损失，使模型聚焦于对困难样本的学习。为了讲解Focal Loss，我们首先来回忆一下交叉熵损失函数，其定义如下：<br>$$<br>\mathrm{CE}(p, y)=\left{\begin{array}{ll}<br>{-\log (p)} &amp; {\text { if } y=1} \<br>{-\log (1-p)} &amp; {\text { otherwise }}<br>\end{array}\right.<br>$$<br>其中，$y \in{\pm 1}$ 表示正负类别，$p\in[0,1]$ 表示预测为正样本的概率，为了符号上方便，定义 $p_t$:<br>$$<br>\begin{aligned}<br>p_{\mathrm{t}} &amp;=\left{\begin{array}{ll}<br>{p} &amp; {\text { if } y=1} \<br>{1-p} &amp; {\text { otherwise }}<br>\end{array}\right.\<br>\end{aligned}<br>$$<br>然后，重写交叉熵损失函数如下：<br>$$<br>\mathrm{CE}(p, y)=\mathrm{CE}\left(p_{\mathrm{t}}\right)=-\log \left(p_{\mathrm{t}}\right)<br>$$<br>交叉熵损失函数如下图的蓝色曲线所示，可以看出即便对于易分类样本 ($p_t&gt;0.5$)，也依然存在着不小的损失，当大量的这些易分类样本的损失累加的时候，这些小的损失和会主导梯度下降方向，淹没难分样本的损失，从而使得网络学习不到那些少量的困难样本的特征。</p>
<p><img src="image/1578881809989.png" alt="1578881809989"></p>
<p>根据以往的经验，解决类别不平衡的一个办法，是引入调节因子 $\alpha \in [0,1]$ 来加权正样本，并用 $1-\alpha$ 来加权负样本，从而平衡正负样本比例，形如下式：<br>$$<br>\mathrm{CE}\left(p_{\mathrm{t}}\right)=-\alpha_t\log \left(p_{\mathrm{t}}\right)<br>$$<br>上述式子的引入，可以平衡正负样本，但是依旧无法平衡难易样本。为此，作者提出了Focal Loss，来控制上述两种不平衡现象，作者使用 $(1-p_t)^\gamma$ 作为调节因子（其中 $\gamma \geq 0$），这样，随着置信度概率增大，上述调节因子将减少，从而可以起到弱化简单样本损失的效果。<br>$$<br>\mathrm{FL}\left(p_{\mathrm{t}}\right)=-\left(1-p_{\mathrm{t}}\right)^{\gamma} \log \left(p_{\mathrm{t}}\right)<br>$$<br>上述 Focal Loss，使得调节因子可以对难易样本进行不同的加权，使得易分类样本的损失降低，并且这种衰减还随着置信度的提升，指数增长，这使得网络更加专注于对难分样本的训练，并且只需要聚焦于对参数 $\gamma$ 的调节，$\gamma$ 对损失的影响如上图所示，可以看出 Focal Loss 的的确可以对难易样本进行不同程度的衰减，很好的起到难以样本均衡的效果，当 $\gamma =0$ 的时候，Focal Loss 又退回到交叉熵损失函数。</p>
<p>作者还表示，Focal Loss 还可以进一步优化成其他一些变体形式，并且经过反复调节，可以带来一些增益，但是相应的参数会变多，函数的复杂程度也会增高，如：<br>$$<br>\mathrm{FL}\left(p_{\mathrm{t}}\right)=-\alpha_{\mathrm{t}}\left(1-p_{\mathrm{t}}\right)^{\gamma} \log \left(p_{\mathrm{t}}\right)<br>$$<br>对于上述形式的Focal Loss，作者实验发现：$\gamma=2, \alpha=0.25$ 时的效果最好。并且实验证明，<strong>对简单负样本的抑制作用要比简单正样本的作用更大</strong>，这也符合目标检测网络的需求。</p>
<h3 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h3><p>RetinaNet 的网络结构如图所示，由负责特征提取的FPN结构的 backbone 网络以及分类与回归两个子网络组成。</p>
<p><img src="image/1578901140174.png" alt="1578901140174"></p>
<p><strong>Backbone</strong></p>
<p>RetinaNet 以 ResNet 作为基础网络，在它的基础上利使用自顶而下和横向连接的FPN结构，来实现多尺度特征融合，以构造兼具高分辨率和高语义特征的特征金字塔。FPN 输出的各层 feature map 的通道数固定为 256，FPN的许多具体细节不是至关重要的，但是这种结构是多尺度特征融合的结构很重要，可以提高网络最终的AP。</p>
<p><strong>Anchors</strong> </p>
<p>RetinaNet 在各层分别设置不同尺度和长宽比的 anchor，每个点设置三种不同的长宽比 <strong>{1:2,1:1,2:1}</strong>，并设置三种不同尺寸 <strong>{$2^0,2^{1/3},2^{2/3}$}</strong>， 因此每个点预测9个anchors。每个 anchor 负责预测一个 $K$ 维的类别矢量，和一个4维的位置矢量。RetinaNet 的匹配方法如下：将每个 anchor 分配给与之IOU大于0.5的 groundtruth ，作为该实际边界框的正样本，然后将IOU小于0.4的anchor，作为其负样本，阈值介于[0.4,0.5]之间的anchor不参与训练。根据上述方法完成匹配之后，根据每个anchor匹配到得groundtruth的类别，对$K$维类别矢量进行one-hot编码，将对应分量置1，其余分量置0，以标记正负样本。</p>
<p><strong>分类网络</strong></p>
<p>分类网络是一个全卷积神经网络，它的结构很简单，先由4层级联的 $W<em>H</em>256$ 的卷积层和 $ReLu$ 激活层进行转换，最后得到  $W<em>H</em>KA$ 的输出，表示对尺寸为 $W*H$ 的特征图上的每一个点的 $A$ 个 anchor，预测 $K$ 个类别概率。</p>
<p><strong>回归网络</strong></p>
<p>回归网络也是一个全卷积神经网络，它的结构与分类网络基本一致，最后得到  $W<em>H</em>4K$ 的输出，表示对尺寸为 $W*H$ 的特征图上的每一个点的 $A$ 个 anchors，预测4个位置信息，以用于回归坐标的偏移量。</p>
<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p><strong>损失函数设置</strong></p>
<p>SSD 等算法确定完正负样本后，为了控制正负样本比，仅选择少部分anchors来计算损失，而 Focal Loss 则对所有匹配上的正负样本来计算损失（注：仅是对所有匹配上的anchor进行归一化，而非所有的anchors），并对所有匹配上的anchors的损失进行归一化处理。这样做的理由是，Focal Loss 对易分样本的损失可以忽略不计，因此可以对所有匹配上的样本计算损失。作者实验通过实验发现：$\gamma=2, \alpha=0.25$ 时的效果最好。</p>
<p><strong>模型初始化</strong></p>
<p>对于二分类问题，一般会将为正负样初始化为等概率。然而，在正负样本极度不均衡的情况下，这种初始化会导致负样本的损失在训练初始阶段占据主导地位，从而导致训练不稳定。为了解决上述问题，我们将正样本的初始值设置的很小，从而加大其初始损失。具体地，作者将分类网络的最后一层的所有偏置设置为：$-log((1-p)/p)$ ，其中 $p$ 作者设置为 0.01，这样就可以得到一个很小的偏置，从而加大正样本的损失。作者通过实验证明，这种初始化策略无论对于普通的交叉熵损失函数还是对于 Focal Loss 都会提高训练的稳定性。</p>
<h2 id="总结概括"><a href="#总结概括" class="headerlink" title="总结概括"></a>总结概括</h2><p>在本文中，作者认为类别不平衡是阻碍one-stage目标检测算法精度的主要原因，为了解决这个问题，作者对交叉熵损失函数进行改机，提出了Focal Loss 这种新的分类损失函数，通过损失函数来减弱这种不均衡现象，弱化简单样本的损失，从而使得网络更加专注于对难分样本的学习。作者还提出了 RetinaNet 这种单阶段的目标检测网络，来配合Focal Loss进行检测，实验证明，RetinaNet 兼顾了one-stage 算法的检测速度和two-stage算法的检测精度，达到了SOTA水平。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ARetinaNet/" data-id="ck5jlw19p0002gil71xu4g6na" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-目标检测：SSD" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ASSD/" class="article-date">
  <time datetime="2020-01-18T13:06:37.728Z" itemprop="datePublished">2020-01-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ASSD/">目标检测：SSD</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h1><p>[TOC]</p>
<h2 id="匹配算法"><a href="#匹配算法" class="headerlink" title="匹配算法"></a>匹配算法</h2><ol>
<li>计算每个default box 与每个ground truth的IOU，然后根据IOU分两步匹配，以确定正负样本。</li>
<li>第一步：将每个 groundtruth 匹配给与之IOU最大的 default box，保证每个 groundtruth 至少有一个 default box 与之匹配。</li>
<li>第二步：将剩余 default box 匹配给与之IOU大于某阈值(0.5)的 groundtruth，这样就允许网络对多个重叠的default box进行预测，以增加正样本的个数，提高召回率。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注：每个default box只能分给一个groundtruth，即只负责预测一个groundtruth，但每个groundtruth可以对应多个default box，即每个groudtruth可以由多个default box来预测，从而提高预测性能。所有匹配上的default box作为正样本，未匹配上的作为负样本。</span><br></pre></td></tr></table></figure>



<p>##　难分负样本挖掘</p>
<p>在生成 default boxes 之后，会产生很多个符合 groundtruth 的 positive boxes（候选正样本集），但同时，不符合 groundtruth 也很多，而且这个 negative boxes（候选负样本集），远多于 positive boxes。这会造成 正负样本之间的不均衡，训练的时候朝着负样本的方向学习，造成较大的分类误差（比如有100个样本，10个正样本，90个负样本，那只要全部预测为负样本，分类准确度却达到了90%，可见这是极度不合理的）。为了均衡正负样本比例，SSD使用了难分负样本挖掘算法，只选择分类损失最大的负样本来求损失，并设置正负样本比例为1:3。</p>
<ol>
<li><p>首先，计算每个 default box 针对每个 groundtruth 的分类损失。</p>
</li>
<li><p>其次， 筛选default boxes， 计算完所有default boxes 的分类 loss后，按照 loss 排序，选择 loss 较大且与任意 groundtruth 之间的 IOU 小于 阈值neg_overlap 的样本中的前 3*num_positive 个负样本来计算分类损失，保证留下的负样本“够坏”，同时保证1:3的正负比例。</p>
</li>
<li><p>最后，这正负比为1:3的部分default boxes就是筛选全体default box后剩下的prior boxes，用这些prior box作为参考，对所有预测框其进行分类和回归，进行反向传播更新网络参数，即训练。</p>
</li>
</ol>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><blockquote>
<p>SSD原理解析：</p>
<ul>
<li><a href="https://blog.csdn.net/Gentleman_Qin/article/details/84403313" target="_blank" rel="noopener">https://blog.csdn.net/Gentleman_Qin/article/details/84403313</a></li>
</ul>
<p>SSD源码(Pytorch):</p>
<ul>
<li><a href="https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py" target="_blank" rel="noopener">https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py</a></li>
</ul>
<p>SSD源码解析：</p>
<ul>
<li><p><a href="https://blog.csdn.net/h__ang/article/details/90316220" target="_blank" rel="noopener">https://blog.csdn.net/h__ang/article/details/90316220</a></p>
</li>
<li><p><a href="https://hellozhaozheng.github.io/z_post/PyTorch-SSD/#build_ssd" target="_blank" rel="noopener">https://hellozhaozheng.github.io/z_post/PyTorch-SSD/#build_ssd</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/63221490" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63221490</a></p>
</li>
</ul>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ASSD/" data-id="ck5jlw19q0003gil700bw0lzs" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/18/hello-world/" class="article-date">
  <time datetime="2020-01-18T12:46:49.664Z" itemprop="datePublished">2020-01-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/18/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/01/18/hello-world/" data-id="ck5jlw19i0000gil7eafm8ffq" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测：小目标检测</a>
          </li>
        
          <li>
            <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9A%E7%9B%B8%E5%85%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">目标检测：相关基础知识</a>
          </li>
        
          <li>
            <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9AFPN/">目标检测：FPN</a>
          </li>
        
          <li>
            <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ARetinaNet/">目标检测：RetinaNet</a>
          </li>
        
          <li>
            <a href="/2020/01/18/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ASSD/">目标检测：SSD</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>